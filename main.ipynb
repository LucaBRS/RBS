{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-24T21:30:23.020000400Z",
     "start_time": "2023-10-24T21:30:21.027973100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\lucab\\AppData\\Local\\Temp\\ipykernel_17504\\920047055.py:56: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "WARNING:tensorflow:From C:\\Users\\lucab\\AppData\\Local\\Temp\\ipykernel_17504\\920047055.py:59: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "[VocabularyListCategoricalColumn(key='ext_weather', vocabulary_list=('sole', 'pioggia ', 'nebbia ', 'pioggia'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='date', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='iaq', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='electrosmog_lf', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='wifi_level', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='wifi_n', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='temperature', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='humidity', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='air_pressure', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='ambient_light', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='tvoc', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='co2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='co2e', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='pm10', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='pm25', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='sound', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='electrosmog_hf', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='device_id', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='ext_temperature', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='ext_humidity', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='ext_wind', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='ext_pressure', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='pm10_ext', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='pm25_ext', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "all_meteo = pd.read_csv('./resources/concat_files/all_pm_meteo_153.csv', parse_dates=['date'])\n",
    "# all_meteo['date']=pd.to_datetime(all_meteo['date'])\n",
    "all_meteo.sort_values(by=['date'], ascending=True, ignore_index=True, inplace=True)\n",
    "CATEGORICAL_COLUMNS = ['ext_weather']\n",
    "NUMERICAL_COLUMNS = ['date',\n",
    "                     'iaq',\n",
    "                     'electrosmog_lf',\n",
    "                     'wifi_level',\n",
    "                     'wifi_n',\n",
    "                     'temperature',\n",
    "                     'humidity',\n",
    "                     'air_pressure',\n",
    "                     'ambient_light',\n",
    "                     'tvoc',\n",
    "                     'co2',\n",
    "                     'co2e',\n",
    "                     'pm10',\n",
    "                     'pm25',\n",
    "                     'sound',\n",
    "                     'electrosmog_hf',\n",
    "                     'device_id',\n",
    "                     'ext_temperature',\n",
    "                     'ext_humidity',\n",
    "                     'ext_wind',\n",
    "                     'ext_pressure',\n",
    "                     'pm10_ext',\n",
    "                     'pm25_ext']\n",
    "\n",
    "# i will define a \"rule\" to divide the data between training and testing data, base on a date interval\n",
    "end_date_train = '2021-12-31'\n",
    "end_date_validation = '2021-12-31'\n",
    "start_date_test = '2022-01-01'\n",
    "\n",
    "train_data = all_meteo[all_meteo['date'] < end_date_train].drop(columns=['date'])\n",
    "test_data = all_meteo[all_meteo['date'] > start_date_test].drop(columns=['date'])\n",
    "\n",
    "#X_train are all the independent variables \n",
    "X_train = train_data.drop(columns=['iaq'])\n",
    "#y_train is the target variable \n",
    "y_train = train_data['iaq']\n",
    "\n",
    "X_eval = test_data.drop(columns=['iaq'])\n",
    "y_eval = test_data['iaq']\n",
    "# now i need to define the feature columns:\n",
    "feature_columns=[]\n",
    "\n",
    "#i will loop through the categorical column in order to create a dictionary\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary= train_data[feature_name].unique()\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name,vocabulary))\n",
    "\n",
    "for feature_name in NUMERICAL_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype=tf.float32))\n",
    "    \n",
    "print(feature_columns  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "89f33377034d3a92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "['date',\n",
    " 'iaq',\n",
    " 'electrosmog_lf',\n",
    " 'wifi_level',\n",
    " 'wifi_n',\n",
    " 'temperature',\n",
    " 'humidity',\n",
    " 'air_pressure',\n",
    " 'ambient_light',\n",
    " 'tvoc',\n",
    " 'co2',\n",
    " 'co2e',\n",
    " 'pm10',\n",
    " 'pm25',\n",
    " 'sound',\n",
    " 'electrosmog_hf',\n",
    " 'device_id',\n",
    " 'ext_temperature',\n",
    " 'ext_humidity',\n",
    " 'ext_wind',\n",
    " 'ext_pressure',\n",
    " 'pm10_ext',\n",
    " 'pm25_ext']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a4768e7a84ccdd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4cf0c26d5bcf8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
